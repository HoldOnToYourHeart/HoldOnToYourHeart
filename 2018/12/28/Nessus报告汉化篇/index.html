<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Nessus报告汉化篇一(数据准备阶段) | 业精于勤荒于嬉</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前言　就笔者目前在工作中使用过的众多扫描器来看，即使是使用免费版Nessus，无论是从扫描的准确度还是漏洞更新的及时性来看，都完虐国内大多数付费版的扫描器。　虽然比较好用，但是Nessus并不提供中文的报告文档，这点就比较尴尬，所以我才有了做‘汉化’的这样一个想法。当然这个汉化肯定不是规规矩矩去进行翻译汉化。工作量那么大，当然得使用脚本去进行批量的操作呀！ 准备　在使用Nessus扫描完成之后，导">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="Nessus报告汉化篇一(数据准备阶段)">
<meta property="og:url" content="https://holdontoyourheart.github.io/2018/12/28/Nessus报告汉化篇/index.html">
<meta property="og:site_name" content="业精于勤荒于嬉">
<meta property="og:description" content="前言　就笔者目前在工作中使用过的众多扫描器来看，即使是使用免费版Nessus，无论是从扫描的准确度还是漏洞更新的及时性来看，都完虐国内大多数付费版的扫描器。　虽然比较好用，但是Nessus并不提供中文的报告文档，这点就比较尴尬，所以我才有了做‘汉化’的这样一个想法。当然这个汉化肯定不是规规矩矩去进行翻译汉化。工作量那么大，当然得使用脚本去进行批量的操作呀！ 准备　在使用Nessus扫描完成之后，导">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://holdontoyourheart.github.io/2018/12/28/Nessus报告汉化篇/1.jpg">
<meta property="og:image" content="https://holdontoyourheart.github.io/2018/12/28/Nessus报告汉化篇/2.jpg">
<meta property="og:image" content="https://holdontoyourheart.github.io/2018/12/28/Nessus报告汉化篇/3.jpg">
<meta property="og:image" content="https://holdontoyourheart.github.io/2018/12/28/Nessus报告汉化篇/4.jpg">
<meta property="og:updated_time" content="2018-12-28T09:47:38.194Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Nessus报告汉化篇一(数据准备阶段)">
<meta name="twitter:description" content="前言　就笔者目前在工作中使用过的众多扫描器来看，即使是使用免费版Nessus，无论是从扫描的准确度还是漏洞更新的及时性来看，都完虐国内大多数付费版的扫描器。　虽然比较好用，但是Nessus并不提供中文的报告文档，这点就比较尴尬，所以我才有了做‘汉化’的这样一个想法。当然这个汉化肯定不是规规矩矩去进行翻译汉化。工作量那么大，当然得使用脚本去进行批量的操作呀！ 准备　在使用Nessus扫描完成之后，导">
<meta name="twitter:image" content="https://holdontoyourheart.github.io/2018/12/28/Nessus报告汉化篇/1.jpg">
  
    <link rel="alternate" href="/atom.xml" title="业精于勤荒于嬉" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">业精于勤荒于嬉</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://holdontoyourheart.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Nessus报告汉化篇" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/28/Nessus报告汉化篇/" class="article-date">
  <time datetime="2018-12-28T08:04:41.000Z" itemprop="datePublished">2018-12-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Nessus报告汉化篇一(数据准备阶段)
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>　就笔者目前在工作中使用过的众多扫描器来看，即使是使用免费版Nessus，无论是从扫描的准确度还是漏洞更新的及时性来看，都完虐国内大多数付费版的扫描器。<br>　虽然比较好用，但是Nessus并不提供中文的报告文档，这点就比较尴尬，所以我才有了做‘汉化’的这样一个想法。当然这个汉化肯定不是规规矩矩去进行翻译汉化。工作量那么大，当然得使用脚本去进行批量的操作呀！</p>
<h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><p>　在使用Nessus扫描完成之后，导出文档的时候，我们一共有以下几个选项<br><img src="/2018/12/28/Nessus报告汉化篇/1.jpg" alt=""><br>　在这些选项中，我们所需要的就是CSV这个格式的文档，因为想对比于其他文件格式，CSV无疑是最好处理的。具体格式如下：<br><img src="/2018/12/28/Nessus报告汉化篇/2.jpg" alt=""><br>　因为考虑到是利用脚本对进行文档进行处理，那么就必须得有一个独特的标识以便后期进行匹配，那么文档中只有CVE编号可以满足我们这个条件。因为每个CVE编号都是独立的，只要有CVE编号，我们就能准确定位到这个漏洞的详情。<br>　那么问题来了，我们应该怎么利用这个编号来进行工作呢，笔者之前在国内的安全厂商绿盟查看过一些漏洞描述的时候，发现绿盟有一个公开的CVE漏洞库。那么思路就来了，我可以爬取绿盟的漏洞，在本地做一个数据库用于存储漏洞信息。然后便可用于做对比了。<br>　爬虫的我选择的是Python编写脚本进行爬取，毕竟Python写起来方便嘛，在写脚本之前可以先分析一下该如何进行爬取，目标站点有哪些特征可以供我们使用。<br>　如图，我们需要控制的URL中只有一个变量，就是最后的数字，它其实是递增的。那么我们就可以遍历它所有的数据。<br><img src="/2018/12/28/Nessus报告汉化篇/3.jpg" alt=""><br>　在这里我也就不详细去分析爬虫如何爬取数据，这个比较简单，我直接贴代码吧，这代码写了挺久了，当时写这个代码就图了个方便，所以写的也比较渣！哈哈。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"># -*- encoding= &quot;utf-8&quot; -*-</span><br><span class="line"></span><br><span class="line">import pymysql</span><br><span class="line">from threading import Thread</span><br><span class="line">from queue import Queue</span><br><span class="line">import time</span><br><span class="line">import urllib.request</span><br><span class="line">import urllib.parse</span><br><span class="line">from urllib import error</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">class cvespider(Thread):</span><br><span class="line">	def __init__(self,url,q,list,sql):</span><br><span class="line">		super(cvespider,self).__init__()</span><br><span class="line">		self.url = url</span><br><span class="line">		#print (url)</span><br><span class="line">		self.q = q</span><br><span class="line">		self.list = list</span><br><span class="line">		self.sql = sql</span><br><span class="line">		self.values = &#123;&apos;name&apos;: &apos;voidking&apos;,&apos;language&apos;: &apos;cn&apos;&#125;</span><br><span class="line">		self.headers = &#123; &apos;User-Agent&apos;: &apos;User-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos;&#125;</span><br><span class="line">		self.data = data = urllib.parse.urlencode(self.values).encode(encoding=&apos;utf-8&apos;,errors=&apos;ignore&apos;)</span><br><span class="line"></span><br><span class="line">	def run(self):</span><br><span class="line">		self.parse_page()</span><br><span class="line">	def send_request(self,url):</span><br><span class="line">		i = 0</span><br><span class="line">		while i &lt;=3:</span><br><span class="line">			try:</span><br><span class="line">				print (&quot;[* ] 请求url: &quot; + self.url)</span><br><span class="line">				request = urllib.request.Request(url=url, data=self.data,headers=self.headers,method=&apos;GET&apos;)</span><br><span class="line">				response = urllib.request.urlopen(request)</span><br><span class="line">			except Exception as e:</span><br><span class="line">				print (&quot;[*] 请求出错&quot;+ str(e) + &quot;[-]&quot; + self.url)</span><br><span class="line">				i += 1</span><br><span class="line">			else:</span><br><span class="line">				return response</span><br><span class="line">	def parse_page(self):</span><br><span class="line">			response = self.send_request(self.url)</span><br><span class="line">			buff = response.read()</span><br><span class="line">			html = buff.decode(&quot;utf-8&quot;)</span><br><span class="line">			soup = BeautifulSoup(buff,&apos;html.parser&apos;)</span><br><span class="line">			html1 = soup.select(&apos;.vulbar&apos;)</span><br><span class="line"></span><br><span class="line">			vulbar = BeautifulSoup(str(html1),&apos;html.parser&apos;)</span><br><span class="line">			#获取标题</span><br><span class="line">			title = vulbar.select(&apos;div[align=&quot;center&quot;] &gt; b&apos;)[0].get_text()</span><br><span class="line"></span><br><span class="line">			#获取内容</span><br><span class="line">			xitong = str(vulbar.find_all(&apos;b&apos;)[3].get_text()) + str(vulbar.find_all(&apos;blockquote&apos;)[0].get_text())</span><br><span class="line"></span><br><span class="line">			#获取描述</span><br><span class="line">			miaoshu = str(vulbar.find_all(&apos;b&apos;)[4].string)</span><br><span class="line"></span><br><span class="line">			#re匹配详细描述</span><br><span class="line">			info = re.findall(&quot;.*描述.([\s\S]*)建议.&quot;,vulbar.get_text())</span><br><span class="line"></span><br><span class="line">			#匹配修复建议</span><br><span class="line">			xiufu = re.findall(&quot;.*建议.([\s\S*]*)浏览.*&quot;,vulbar.get_text())</span><br><span class="line"></span><br><span class="line">			time.sleep(0.1)</span><br><span class="line">			if &apos;CVE&apos; in vulbar.get_text():</span><br><span class="line">				try:</span><br><span class="line">					cve = re.findall(&quot;ID: (C.*)&quot;,vulbar.get_text())[0]</span><br><span class="line">				except IndexError:</span><br><span class="line">					cve = &apos;&apos;</span><br><span class="line">			else:</span><br><span class="line">				cve = &apos; &apos;</span><br><span class="line">			list_info = (str(title),str(cve),str(info[0]),str(xiufu[0]))</span><br><span class="line">			self.list.append (list_info)</span><br><span class="line">			#print (&apos;[* Title:] &apos;+ str(list_info[0]))</span><br><span class="line">			#转义</span><br><span class="line">			text = pymysql.escape_string(str(list_info[0]))</span><br><span class="line">			#print (&apos;[* text:]&apos; + str(text))</span><br><span class="line">			res = self.db_execute(&quot;select cve_name from cve_list where cve_name=&apos;%s&apos;&quot;%text)</span><br><span class="line">			#print (&apos;[* res:]&apos; + str(res[0]))</span><br><span class="line">			#print (type(res1))</span><br><span class="line">			if not res:</span><br><span class="line">				if text not in res:</span><br><span class="line">					sql = &quot;insert into cve_list(cve_name,cve_number,cve_info,cve_suggest) values(&apos;%s&apos;,&apos;%s&apos;,&apos;%s&apos;,&apos;%s&apos;)&quot; %(str(text),str(list_info[1]),str(list_info[2]),str(list_info[3]))</span><br><span class="line">					print (&apos;[* ]无原始数据-插入数据中...&apos;)</span><br><span class="line">					try:</span><br><span class="line">						self.db_execute(sql)</span><br><span class="line">					except:</span><br><span class="line">						print(&apos;[* error log ]&apos;+self.url)</span><br><span class="line"></span><br><span class="line">			else:</span><br><span class="line">				if str(list_info[0]) not in str(res[0]):</span><br><span class="line">					sql = &quot;insert into cve_list(cve_name,cve_number,cve_info,cve_suggest) values(&apos;%s&apos;,&apos;%s&apos;,&apos;%s&apos;,&apos;%s&apos;)&quot; %(str(text),str(list_info[1]),str(list_info[2]),str(list_info[3]))</span><br><span class="line">					print (&apos;[- ]有原始数据-插入数据中...&apos;)</span><br><span class="line">					try:</span><br><span class="line">						self.db_execute(sql)</span><br><span class="line">					except:</span><br><span class="line">						print(&apos;[* error log ]&apos;+self.url)</span><br><span class="line"></span><br><span class="line">	def db_execute(self,sql):</span><br><span class="line">		db = pymysql.connect(&quot;127.0.0.1&quot;, &quot;root&quot;, &quot;test007&quot;, &quot;cve_data&quot;)</span><br><span class="line">		cursor = db.cursor()</span><br><span class="line">		cursor.execute(sql)</span><br><span class="line">		db.commit()</span><br><span class="line">		results = cursor.fetchall()</span><br><span class="line">		db.close()</span><br><span class="line">		return results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">	q = Queue()</span><br><span class="line">	base_url = &apos;http://www.nsfocus.net/vulndb/&apos;</span><br><span class="line">	url_list = [base_url + str(num) for num in range(50,41949)]</span><br><span class="line">	Thread_list = []</span><br><span class="line">	list = []</span><br><span class="line">	sql = &apos;&apos;</span><br><span class="line">	for url in url_list:</span><br><span class="line">		p = cvespider(url,q,list,sql)</span><br><span class="line">		p.start()</span><br><span class="line">		Thread_list.append(p)</span><br><span class="line">		time.sleep(0.2)</span><br><span class="line">	for i in Thread_list:</span><br><span class="line">		i.join()</span><br><span class="line">	while not q.empty():</span><br><span class="line">		print (&apos;[* ******************]&apos;+ str(q.get()))</span><br><span class="line"></span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line"></span><br><span class="line">	start = time.time()</span><br><span class="line">	main()</span><br><span class="line">	print (&apos;[info]耗时：%s&apos;%(time.time()-start))</span><br></pre></td></tr></table></figure></p>
<p>　效果如图所示<br><img src="/2018/12/28/Nessus报告汉化篇/4.jpg" alt=""><br>　到这里，咱们的前期工作算是准备完成了，下一篇，我将会把如何处理Nessus的文档思路写出来，今天就到这了！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://holdontoyourheart.github.io/2018/12/28/Nessus报告汉化篇/" data-id="cjtom7y3800009sji35i14ce7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/01/02/Nessus报告汉化篇二/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Nessus报告汉化篇二(初步汉化)
        
      </div>
    </a>
  
  
    <a href="/2018/12/28/WEB安全/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">WEB安全</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/杂记/">杂记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安全/">安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/杂记/">杂记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/安全/" style="font-size: 20px;">安全</a> <a href="/tags/杂记/" style="font-size: 10px;">杂记</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/25/模拟环境的渗透测试/">模拟环境的渗透测试</a>
          </li>
        
          <li>
            <a href="/2019/01/02/Nessus报告汉化篇二/">Nessus报告汉化篇二(初步汉化)</a>
          </li>
        
          <li>
            <a href="/2018/12/28/Nessus报告汉化篇/">Nessus报告汉化篇一(数据准备阶段)</a>
          </li>
        
          <li>
            <a href="/2018/12/28/WEB安全/">WEB安全</a>
          </li>
        
          <li>
            <a href="/2018/12/28/个人简介/">自介</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 又如清风袭来<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>